{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22039b0-0ff4-4ee0-a8b7-d38523dde9a2",
   "metadata": {},
   "source": [
    " # What's spacy?\n",
    "SpaCy is free, open-source library for advanced Natural language processing (NLP) in Python.\n",
    "\n",
    "Suppose you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What does the words mean in the context? Who is doing what to whom? What products and compnaies are mentioned in the text? Which texts are simmilar to each other.\n",
    "\n",
    "spacy is designed specifically for production use and helps you build applications that process and \"understand\" large volume of text. It can be used to build information extraction or natural language processing systems, or to pre-process text for deep learning.\n",
    " # What spacy isn't?\n",
    "\n",
    "First, spacy isn't a platform or an \"API\". Unlike a platform, spaCy doesn't provide a software as a service or a web application. It's an open-source library designed to help you build NLP applications, not a consumable service.\n",
    "\n",
    "Second, spacy is not an out-of-the-box chat bot engine. While spaCy can be used to power conversational applications, it's not designed specifically for chat bots, and only provides the underlying text processing capabilities.\n",
    "\n",
    "Third, spacy is not research software. It's built on the latest research, but it's designed to get things done. This leads to fairly different design decisions than NLTK or CoreNLP, which were created as platforms for teaching and research. The main difference is that spaCy is integrated and opinionated. spacy tries to avoid asking the user to choose between multiple algorithms that deliver equivalent functionality. Keeping the menu small lets spacy deliver generally better performance and developer experience.\n",
    "\n",
    "Fourth, spacy is not a company It's an open-source library. The company publishing spaCy and other software is called Explosion Al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e7755-f69b-4501-965e-bb5e6331c1eb",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "spacy is compatible with 64bit of Cython 2.7/3.5+ and runs on Unix/Linux, macOS/OS X and Windows. The latest version of spacy is available over pip and conda.\n",
    "\n",
    "-> Installation with pip in Linux, Windows and macOs/OS X for both version of Python 2.7/3.5+\n",
    "\n",
    "pip install -U spacy or pip install spacy\n",
    "\n",
    "--> Installation with conda in Linux, Windows and macOs/OS X for both version of Python 2.7/3.5+\n",
    "\n",
    "conda install -c conda-forge spacy\n",
    "\n",
    "# Features\n",
    "Here, you'll come across mentions of spacy's features and capabilities.\n",
    "\n",
    "# Statistical models\n",
    "Some of spacy's features works independently, other requires statistical models to be loaded, which enable spacy to predict linguistic annotations-For example, whether a word is a verb or noun. spaCy currently offers statistical models for a variety of languages, which can be installed as individual Python modules. Models can differ in size, speed, memory usage, accuracy, and the data they include. The model you choose always depends upon your use cases and the texts you're working with. For a general use case, the small and the default models are always a good start. They typically include the following components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0f5c1-c9fc-48e1-84da-6550f6667f03",
   "metadata": {},
   "source": [
    "Binary weights for the part-of-speech tagger, dependency parser and named entity recognizer to predict those annotations in context.\n",
    "\n",
    "Lexical entries in the vocabulary, i.e. words and their context-independent attributes like the shape or spelling.\n",
    "\n",
    "Data files like lemmatization rules and lookup tables.\n",
    "\n",
    "Word vectors, i.e. multi-dimensional meaning representations of words that let you determine how similar they are to each other.\n",
    "\n",
    "Configuration options, like the language and processing pipeline settings, to put spacy in the correct state when you load in the model.\n",
    "\n",
    " # Linguistic annotations\n",
    "\n",
    "spacy provides a variety of linguistic annotations to give you insights into a text's grammatical structure. This includes the word types, like the parts of speech, and how the words are related to each other. For example, if you're analyzing text, it makes a huge difference whether a noun is the subject of a sentence, or the object or whether \"google\" is used as a verb, or refers to the website or company in a specific context.\n",
    "\n",
    "Once you've downloaded and installed a model, you can load it via spacy.load() This will retum a Language object containing all components and data needed to process text. We usually call it nip object on a string of text will retum a processed Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46ee6c7-fefc-4e0f-9ce9-9158cce2523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.1.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Using cached numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed numpy-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.2 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.0.2 which is incompatible.\n",
      "streamlit 1.32.0 requires numpy<2,>=1.19.3, but you have numpy 2.0.2 which is incompatible.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4acd98e-3525-4cef-82c8-9dc75e41c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/12.8 MB 812.7 kB/s eta 0:00:16\n",
      "      --------------------------------------- 0.2/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.8 MB 4.0 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.0/12.8 MB 4.6 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.2/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.5/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.0/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.0/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.9/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.3/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.5/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.7/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.0/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fd1b71-52b3-48a9-9386-269e0a492dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus Coronavirus PROPN NNP nsubj Xxxxx True False\n",
      ": : PUNCT : punct : False False\n",
      "Delhi Delhi PROPN NNP compound Xxxxx True False\n",
      "resident resident NOUN NN nsubj xxxx True False\n",
      "tests test VERB VBZ appos xxxx True False\n",
      "positive positive ADJ JJ amod xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "coronavirus coronavirus NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "total total ADJ JJ ROOT xxxx True False\n",
      "31 31 NUM CD nummod dd False False\n",
      "people people NOUN NNS dobj xxxx True False\n",
      "infected infect VERB VBN acl xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "India India PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Test it with a sample text\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India.\")\n",
    "\n",
    "# Iterate over tokens in the doc and print their attributes\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e35858-12df-4130-9bab-76f0a747af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Coronavirus Coronavirus PROPN NNP nsubj Xxxxx True False\n",
      ": : PUNCT : punct : False False\n",
      "Delhi Delhi PROPN NNP compound Xxxxx True False\n",
      "resident resident NOUN NN nsubj xxxx True False\n",
      "tests test VERB VBZ appos xxxx True False\n",
      "positive positive ADJ JJ amod xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "coronavirus coronavirus NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "total total ADJ JJ ROOT xxxx True False\n",
      "31 31 NUM CD nummod dd False False\n",
      "people people NOUN NNS dobj xxxx True False\n",
      "infected infect VERB VBN acl xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "India India PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Install SpaCy\n",
    "!pip install spacy\n",
    "\n",
    "# Cell 2: Download the English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Cell 3: Import SpaCy and use it\n",
    "import spacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Test it with a sample text\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India.\")\n",
    "\n",
    "# Iterate over tokens in the doc and print their attributes\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd7271-61cd-499c-a7c8-c13e3ba2d271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e455253-707b-4661-9858-f963d728c300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b78e4-a745-4fdb-a499-dd13c947abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8aef8-fc83-48e4-9246-6376a51f6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef12948-0f2c-4476-b50d-04d57b9a9051",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "During processing, spaCy first tokenizes the text, i.e. segments it into words, punctuation and so on. This is done by applying rules specific to each language. For example, punctuation at the end of a sentence should be split off-whereas \"U.K.\" should remain one token. Each Doc consists of individual tokens, and we can iterate over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8dac4c-4de1-4f4c-9629-fd24ff88c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp =spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24758b51-f373-4c8a-9a21-0493e091bfc5",
   "metadata": {},
   "source": [
    "First, the raw text is split on whitespace characters, similar to text.split(' '). Then, the tokenizer processes the text from left to right. On each substring, it performs two checks:\n",
    "\n",
    "1. Does the substring match a tokenizer exception rule? For example, \"don't\" does not contain whitespace, but should be split into two tokens, \"do\" and \"n't\", while \"U.K.\" should always remain one token.\n",
    "2. Can a prefix, suffix or infix be split off? For example punctuation like commas, periods, hyphens or quotes.\n",
    "If there's a match, the rule is applied and the tokenizer continues its loop, starting with the newly split substrings. This way, spacy can split complex, nested tokens like combinations of abbreviations and multiple punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2cbef-ec62-4f44-8332-90bc3ccf3cdf",
   "metadata": {},
   "source": [
    " # Part-of-speech(pos) tags and dependencies\n",
    "After tokenization, spaCy can parse and tag a given Doc. This is where the statistical model comes in, which enables spacy to make a prediction of which tag or label most likely applies in this context. A model consists of binary data and is produced by showing a system enough examples for it to make predictions that generalize across the language for example, a word following \"the\" in English is most likely a noun.\n",
    "\n",
    "Linguistic annotations are available as Token Like many NLP libraries, spaCy encodes all strings to hash values to reduce memory usage and improve efficiency. So to get the readable string representation of an attribute, we need to add an underscore_to its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e926360f-84bb-457c-b0ee-c13194b31922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus 14196865665419520621 96 15794550382381185553 429 16072095006890171862 True False\n",
      ": 11532473245541075862 97 11532473245541075862 445 11532473245541075862 False False\n",
      "Delhi 7055494911946032454 96 15794550382381185553 7037928807040764755 16072095006890171862 True False\n",
      "resident 12791935767146688153 92 15308085513773655218 429 13110060611322374290 True False\n",
      "tests 1618900948208871284 100 13927759927860985106 403 13110060611322374290 True False\n",
      "positive 8177200212695065927 84 10554686591937588953 402 13110060611322374290 True False\n",
      "for 16037325823156266367 85 1292078113972184607 443 4088098365541558500 True True\n",
      "coronavirus 12610307704150367228 92 15308085513773655218 439 13110060611322374290 True False\n",
      ", 2593208677638477497 97 2593208677638477497 445 2593208677638477497 False False\n",
      "total 12505506919507411536 84 10554686591937588953 8206900633647566924 13110060611322374290 True False\n",
      "31 16449342687276647362 93 8427216679587749980 12837356684637874264 4620368362210911820 False False\n",
      "people 7593739049417968140 92 783433942507015291 416 13110060611322374290 True False\n",
      "infected 6588266073218020180 100 3822385049556375858 451 13110060611322374290 True False\n",
      "in 3002984154512732771 85 1292078113972184607 443 4370460163704169311 True True\n",
      "India 13756031414435721121 96 15794550382381185553 439 16072095006890171862 True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma, token.pos, token.tag, token.dep,\n",
    "        token.shape, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b21e12b5-f65e-4bb1-9a60-3a2531308d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus 14196865665419520621 96 15794550382381185553 429 16072095006890171862 True False\n",
      ": 11532473245541075862 97 11532473245541075862 445 11532473245541075862 False False\n",
      "Delhi 7055494911946032454 96 15794550382381185553 7037928807040764755 16072095006890171862 True False\n",
      "resident 12791935767146688153 92 15308085513773655218 429 13110060611322374290 True False\n",
      "tests 1618900948208871284 100 13927759927860985106 403 13110060611322374290 True False\n",
      "positive 8177200212695065927 84 10554686591937588953 402 13110060611322374290 True False\n",
      "for 16037325823156266367 85 1292078113972184607 443 4088098365541558500 True True\n",
      "coronavirus 12610307704150367228 92 15308085513773655218 439 13110060611322374290 True False\n",
      ", 2593208677638477497 97 2593208677638477497 445 2593208677638477497 False False\n",
      "total 12505506919507411536 84 10554686591937588953 8206900633647566924 13110060611322374290 True False\n",
      "31 16449342687276647362 93 8427216679587749980 12837356684637874264 4620368362210911820 False False\n",
      "people 7593739049417968140 92 783433942507015291 416 13110060611322374290 True False\n",
      "infected 6588266073218020180 100 3822385049556375858 451 13110060611322374290 True False\n",
      "in 3002984154512732771 85 1292078113972184607 443 4370460163704169311 True True\n",
      "India 13756031414435721121 96 15794550382381185553 439 16072095006890171862 True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "doc= nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma, token.pos, token.tag, token.dep, token.shape, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c01e1e-6e77-4e9a-86fb-409ed4727393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"960859cf853648f485ad06eefa98b47d-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Google,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">crack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">down</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">fake</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">coronavirus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">apps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-960859cf853648f485ad06eefa98b47d-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-960859cf853648f485ad06eefa98b47d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Google, Apple crack down on fake coronavirus apps\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe45bf-a20a-4c4e-85ba-b5f3ce25fce5",
   "metadata": {},
   "source": [
    " # Named Entities\n",
    "A named entity is a \"real-world object\" that's assigned a name - for example, a person, a country, a product or a book title. spacy can recognize various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn't always work perfectly and might need some tuning later, depending on your use case.\n",
    "Named entities are available as the ents property of a Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca8d69-e121-4fc9-bfee-1ddcf7e0a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp =spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1296651-2dfa-4ce1-821f-b54a439600fb",
   "metadata": {},
   "source": [
    " # Visualizing the Named Entity recognizer\n",
    "The entity visualizer, ent, highlight named entities and their label in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7891e-d23f-44f1-a09e-df389d4ee7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "text = \"Coronavirus: Delhi resident tests positive for coronavirus, total 31 people infected in India\"\n",
    "nlp = spacy.load(\"en core web sm\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")\n",
    "#https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd2af3-d3fe-4952-b693-903ae4fac2d8",
   "metadata": {},
   "source": [
    " # Words vector and similarity\n",
    "Similarity is determined by comparing word vectors or 'word embeddings\", multi-dimensional meaning representations of a word. Word vectors can be generated using an algorithm like word2vec and usually look like this:\n",
    "\n",
    "### Important_note:\n",
    "To make them compact and fast, spacy's small models(all the pacakages end with sm) don't ship with the word vectors, and only include context-sensitive tensors. This means you can still use the similarity() to compare documents, tokens and spans - but result won't be as good, and individual tokens won't have any vectors is assigned. So, in orders to use real word vectors, you need to download a larger model:\n",
    "\n",
    "python-m spacy download en core web md\n",
    "\n",
    "\n",
    "Models that come with built-in word vectors make them available as the Token.vector attribute. Doc.vector and Span.vector will default to an average of their token vectors. You can also check if a token has a vector assigned, and get the L2 norm, which can be used to normalize vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3b9ed-c9fc-4434-b51c-639176faf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python- spacy download en_core_web_md\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en core web md\")\n",
    "import en_core_web_md\n",
    "nlp_en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bd461-6cbc-4674-822f-e5e356e28bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
